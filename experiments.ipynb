{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c8922f4-67b8-4feb-81bd-36a8e2f61b14",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:10px; font-size:20px\">\n",
    "Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fa5dc67-cf47-49c0-ba4b-1af2c08fa059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dafa2d2f-3d08-4422-876d-776965d9b69b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -otocore (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pip in /opt/conda/lib/python3.8/site-packages (23.2.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -otocore (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -otocore (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: boto3 in /opt/conda/lib/python3.8/site-packages (1.28.46)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.46 in /opt/conda/lib/python3.8/site-packages (from boto3) (1.31.46)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from boto3) (0.6.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.8/site-packages (from botocore<1.32.0,>=1.31.46->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.32.0,>=1.31.46->boto3) (1.26.14)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.46->boto3) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -otocore (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -otocore (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sagemaker in /opt/conda/lib/python3.8/site-packages (2.185.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.28.46)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.23.5)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (3.20.2)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (4.13.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (23.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.5.3)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.8/site-packages (from sagemaker) (4.19.0)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.8/site-packages (from sagemaker) (3.10.0)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.46 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.31.46)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.13.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (5.10.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (2023.7.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (0.10.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2022.7.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.8/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.32.0,>=1.31.46->boto3<2.0,>=1.26.131->sagemaker) (1.26.14)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -otocore (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -otocore (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (1.12.1+cpu)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch) (4.4.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -otocore (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -otocore (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (0.13.1+cpu)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torchvision) (4.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from torchvision) (2.28.2)\n",
      "Requirement already satisfied: torch==1.12.1 in /opt/conda/lib/python3.8/site-packages (from torchvision) (1.12.1+cpu)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision) (2022.12.7)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -otocore (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# update boto3 and sagemaker to ensure latest SDK version\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install --upgrade boto3\n",
    "!{sys.executable} -m pip install --upgrade sagemaker\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0d32c32-0749-48a4-8d73-7ea617ba8428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -otocore (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchinfo in /opt/conda/lib/python3.8/site-packages (1.8.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -otocore (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac4f97d-b358-4740-bcb1-dc8e76209b0b",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:10px; font-size:20px\">\n",
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0a93c0c-5cc1-4bd3-9b68-f4532832e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.utils import unique_name_from_base\n",
    "import boto3\n",
    "\n",
    "# Model\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Aux\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "import time\n",
    "import sklearn\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f08daa-7a58-4137-ba29-59a701bc0887",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:10px; font-size:20px\">\n",
    "Train Script"
   ]
  },
  {
   "cell_type": "raw",
   "id": "595066c1-e709-4bba-a2eb-02d4dea9c34b",
   "metadata": {},
   "source": [
    "!mkdir -p script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4a466ed-80db-461e-acc7-850d106b080d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./script/toy_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./script/toy_model.py\n",
    "\n",
    "#=======================================================================\n",
    "#                               SET UP\n",
    "#=======================================================================\n",
    "\n",
    "# ensure that the latest version of the SageMaker SDK is available\n",
    "import os\n",
    "\n",
    "os.system(\"pip install -U sagemaker\")\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import traceback\n",
    "import sys\n",
    "import time\n",
    "from os.path import join\n",
    "import boto3\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.experiments.run import load_run\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout)) # Sends logs to std out\n",
    "\n",
    "# Saving copy of logs to .json file\n",
    "if \"SAGEMAKER_METRICS_DIRECTORY\" in os.environ:\n",
    "    log_file_handler = logging.FileHandler(\n",
    "        join(os.environ[\"SAGEMAKER_METRICS_DIRECTORY\"], \"metrics.json\")\n",
    "    )\n",
    "    formatter = logging.Formatter(\n",
    "        \"{'time':'%(asctime)s', 'name': '%(name)s', \\\n",
    "        'level': '%(levelname)s', 'message': '%(message)s'}\",\n",
    "        style=\"%\",\n",
    "    )\n",
    "    log_file_handler.setFormatter(formatter)\n",
    "    logger.addHandler(log_file_handler)\n",
    "\n",
    "#=======================================================================\n",
    "#                               MODEL\n",
    "#=======================================================================\n",
    "\n",
    "class CIFAR10Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 512)\n",
    "        self.bn5 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn6 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn4(self.conv4(x))))\n",
    "        \n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(-1, 256)\n",
    "        \n",
    "        x = F.leaky_relu(self.bn5(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.bn6(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "#=======================================================================\n",
    "#                               EVAL LOG FUNCTION\n",
    "#=======================================================================\n",
    "\n",
    "\n",
    "def log_performance(model, data_loader, device, epoch, run, metric_type=\"Test\"):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            # loss += torch.nn.functional.nll_loss(\n",
    "            #     output, target, reduction=\"sum\"\n",
    "            # ).item()  # sum up batch loss\n",
    "            criterion = nn.CrossEntropyLoss(reduction = \"sum\")\n",
    "            loss += criterion(output, target).item()\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    loss /= len(data_loader.dataset)\n",
    "    accuracy = 100.0 * correct / len(data_loader.dataset)\n",
    "    # ⛳️SM: log metrics\n",
    "    run.log_metric(name=metric_type + \":loss\", value=loss, step=epoch)\n",
    "    run.log_metric(name=metric_type + \":accuracy\", value=accuracy, step=epoch)\n",
    "    logger.info(\n",
    "        \"{} Average loss: {:.4f}, {} Accuracy: {:.4f}%;\\n\".format(\n",
    "            metric_type, loss, metric_type, accuracy\n",
    "        )\n",
    "    )\n",
    "\n",
    "#=======================================================================\n",
    "#                               TRAIN FUNCTION\n",
    "#=======================================================================\n",
    "\n",
    "def train_model(\n",
    "    run, \n",
    "    train_set, \n",
    "    test_set,\n",
    "    epochs, \n",
    "    lr\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        run (sagemaker.experiments.run.Run): SageMaker Experiment run object\n",
    "        train_set (torchvision.datasets.mnist.MNIST): train dataset\n",
    "        test_set (torchvision.datasets.mnist.MNIST): test dataset\n",
    "        data_dir (str): local directory where the MNIST datasource is stored\n",
    "        optimizer (str): the optimization algorthm to use for training your CNN\n",
    "                         available options are sgd and adam\n",
    "        epochs (int): number of complete pass of the training dataset through the algorithm\n",
    "        hidden_channels (int): number of hidden channels in your model\n",
    "    \"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size= 64, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size= 500, shuffle=False)\n",
    "    \n",
    "    #📍Logger: Progress Output\n",
    "    logger.info(\n",
    "        \"Processes {}/{} ({:.0f}%) of train data\".format(\n",
    "            len(train_loader.sampler),\n",
    "            len(train_loader.dataset),\n",
    "            100.0 * len(train_loader.sampler) / len(train_loader.dataset),))\n",
    "\n",
    "    logger.info(\n",
    "        \"Processes {}/{} ({:.0f}%) of test data\".format(\n",
    "            len(test_loader.sampler),\n",
    "            len(test_loader.dataset),\n",
    "            100.0 * len(test_loader.sampler) / len(test_loader.dataset),))\n",
    "    \n",
    "    # Train Set Up\n",
    "    model = CIFAR10Net().to(device)\n",
    "    # model = torch.nn.DataParallel(model) # if multiple GPU's\n",
    "    lr = lr\n",
    "    log_interval = 100\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    # ⛳️SM: log model run parameters\n",
    "    run.log_parameters({\"optimizer\": \"Adam\",\n",
    "                        \"epochs\": epochs,})\n",
    "\n",
    "    # Train Loop = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(\"Training Epoch:\", epoch)\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader, 1):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            # loss = torch.nn.functional.nll_loss(output, target)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #📍 Logger: Train Status\n",
    "            if batch_idx % log_interval == 0:\n",
    "                logger.info(\n",
    "                    \"Train Epoch: {} [{}/{} ({:.0f}%)], Train Loss: {:.6f};\".format(\n",
    "                        epoch,\n",
    "                        batch_idx * len(data),\n",
    "                        len(train_loader.sampler),\n",
    "                        100.0 * batch_idx / len(train_loader),\n",
    "                        loss.item(),\n",
    "                    )\n",
    "                )\n",
    "        # ⛳️ SM: Metric Logging\n",
    "        run.log_metric(name = 'epoch', value = epoch)\n",
    "        log_performance(model, train_loader, device, epoch, run, \"Train\")\n",
    "        log_performance(model, test_loader, device, epoch, run, \"Test\")\n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "        \n",
    "    # ⛳️ SM: Confusion Matrix Logging\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            run.log_confusion_matrix(target, pred, \"Confusion-Matrix-Test-Data\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    hidden_channels = int(os.environ.get(\"hidden_channels\", \"5\"))\n",
    "    kernel_size = int(os.environ.get(\"kernel_size\", \"5\"))\n",
    "    dropout = float(os.environ.get(\"dropout\", \"0.5\"))\n",
    "    model = torch.nn.DataParallel(Net(hidden_channels, kernel_size, dropout))\n",
    "    with open(os.path.join(model_dir, \"model.pth\"), \"rb\") as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "        return model.to(device)\n",
    "\n",
    "\n",
    "def save_model(model, model_dir, run):\n",
    "    logger.info(\"Saving the model.\")\n",
    "    path = os.path.join(model_dir, \"model.pth\")\n",
    "    # recommended way from http://pytorch.org/docs/master/notes/serialization.html\n",
    "    torch.save(model.cpu().state_dict(), path)\n",
    "\n",
    "#=======================================================================\n",
    "#                               ARGPARSE\n",
    "#=======================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    try:\n",
    "        parser = argparse.ArgumentParser()\n",
    "\n",
    "        parser.add_argument(\"--epochs\",type=int,default=10,metavar=\"N\",help=\"number of epochs to train (default: 10)\")\n",
    "        parser.add_argument('--lr', type=float, default=0.01)\n",
    "\n",
    "        # Data, model, and output directories\n",
    "        # parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "        parser.add_argument('--training', type=str, default=os.environ['SM_CHANNEL_TRAINING'])\n",
    "        parser.add_argument('--validation', type=str, default=os.environ['SM_CHANNEL_VALIDATION'])\n",
    "        # parser.add_argument('--output-data-dir', type=str, default=os.environ['SM_OUTPUT_DATA_DIR'])\n",
    "\n",
    "        # Container environment\n",
    "        parser.add_argument(\"--hosts\", type=list, default=json.loads(os.environ[\"SM_HOSTS\"]))\n",
    "        parser.add_argument(\"--current-host\", type=str, default=os.environ[\"SM_CURRENT_HOST\"])\n",
    "        parser.add_argument(\"--model-dir\", type=str, default=os.environ[\"SM_MODEL_DIR\"])\n",
    "        parser.add_argument(\"--num-gpus\", type=int, default=os.environ[\"SM_NUM_GPUS\"])\n",
    "        parser.add_argument(\"--region\", type=str, default=\"us-east-1\", help=\"SageMaker Region\")\n",
    "\n",
    "        args, _ = parser.parse_known_args()\n",
    "\n",
    "# = = = = = = = = = = = = = = DATA = = = = = = = = = = = = = = = = = = = =\n",
    "\n",
    "        load_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                             transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "        train_set = torchvision.datasets.ImageFolder(root=args.training, transform=load_transform)\n",
    "        test_set = torchvision.datasets.ImageFolder(root=args.validation, transform=load_transform)\n",
    "\n",
    "#=======================================================================\n",
    "#                               RUN\n",
    "#=======================================================================\n",
    "\n",
    "        session = Session(boto3.session.Session(region_name=args.region))\n",
    "\n",
    "        with load_run(sagemaker_session=session) as run:\n",
    "\n",
    "            model = train_model(\n",
    "                run,\n",
    "                train_set = train_set,\n",
    "                test_set = test_set,\n",
    "                epochs=args.epochs,\n",
    "                lr = args.lr\n",
    "            )\n",
    "            save_model(model, args.model_dir, run)\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(\"Exception occurred: %s\", e)\n",
    "        logger.error(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488c12e-8b0b-4bac-a2df-0b10872d4fc4",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:10px; font-size:20px\">\n",
    "SageMaker Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf786ce-6237-45d8-84b7-8d81cf4ac914",
   "metadata": {},
   "source": [
    "Below is a diagram outlining the various components of an SM Experiments run and how they must be structured in your code. Steps below involve:\n",
    "- Creation of a SageMaker experiment name (which can be thought of as a project or exploration containing all of your runs)\n",
    "- Creation of desired hyperparameter search space (the cartesian product of all possible HP combinations)\n",
    "- A for-loop that creates an indexed experiment run for every HP combination:\n",
    "    - Every HP combination is passed to an Estimator object (training job) that trains the model under its respective configuration\n",
    "    - Training metadata and model artifacts are saved between a specified s3 location and a SM Experiments database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdd6b4e-e976-42e2-afc6-f3f2418d6e3c",
   "metadata": {},
   "source": [
    "<img src=\"./images/sm_experiments_overview.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9f4196-fcd6-4a4c-9a79-f67fa62ba1b1",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:10px; font-size:20px\">\n",
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c8fe8fd-21a9-4d2e-ab62-6dc330ab0ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'epochs': 10, 'lr': 0.001, 'region': 'us-east-1'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Set Region - annoying SM detail that it must be passed as an arg\n",
    "region = Session().boto_session.region_name\n",
    "\n",
    "param_grid = {\n",
    "    'lr': [0.001],\n",
    "    'epochs': [10],\n",
    "    'region':[region]\n",
    "}\n",
    "\n",
    "param_combinations = list(ParameterGrid(param_grid))\n",
    "param_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd0de2-7876-42e3-b562-fad61001c495",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:10px; font-size:20px\">\n",
    "Train Model w/ Run Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ccd4e6d-32a4-426e-9b11-4012635d8887",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Sources\n",
    "full_train_s3_path = f's3://pytorch-aws-train-deploy-project/cifar-dataset/foldered-dataset/train/'\n",
    "full_val_s3_path = f's3://pytorch-aws-train-deploy-project/cifar-dataset/foldered-dataset/val/'\n",
    "\n",
    "subset_train_s3_path = f's3://pytorch-aws-train-deploy-project/cifar-dataset/foldered-dataset-subset/train/'\n",
    "subset_val_s3_path = f's3://pytorch-aws-train-deploy-project/cifar-dataset/foldered-dataset-subset/val/'\n",
    "\n",
    "run_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ad72164-45ef-4580-a187-55153dcccd0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "run-2\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-09-12-20-24-06-264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-12 20:24:06 Starting - Starting the training job...\n",
      "2023-09-12 20:24:22 Starting - Preparing the instances for training......\n",
      "2023-09-12 20:25:23 Downloading - Downloading input data.........\n",
      "2023-09-12 20:26:59 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-09-12 20:27:05,284 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-09-12 20:27:05,286 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-09-12 20:27:05,288 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-09-12 20:27:05,299 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-09-12 20:27:05,301 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-09-12 20:27:05,598 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-09-12 20:27:05,600 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-09-12 20:27:05,614 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-09-12 20:27:05,616 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-09-12 20:27:05,630 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-09-12 20:27:05,633 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-09-12 20:27:05,644 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10,\n",
      "        \"lr\": 0.001,\n",
      "        \"region\": \"us-east-1\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"pytorch-training-2023-09-12-20-24-06-264\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://pytorch-aws-train-deploy-project/pytorch-training-2023-09-12-20-24-06-264/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"toy_model\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"toy_model.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":10,\"lr\":0.001,\"region\":\"us-east-1\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=toy_model.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=toy_model\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://pytorch-aws-train-deploy-project/pytorch-training-2023-09-12-20-24-06-264/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10,\"lr\":0.001,\"region\":\"us-east-1\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"pytorch-training-2023-09-12-20-24-06-264\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://pytorch-aws-train-deploy-project/pytorch-training-2023-09-12-20-24-06-264/source/sourcedir.tar.gz\",\"module_name\":\"toy_model\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"toy_model.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"10\",\"--lr\",\"0.001\",\"--region\",\"us-east-1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_REGION=us-east-1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 toy_model.py --epochs 10 --lr 0.001 --region us-east-1\u001b[0m\n",
      "\u001b[34m2023-09-12 20:27:06,280 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sagemaker in /opt/conda/lib/python3.8/site-packages (2.132.0)\u001b[0m\n",
      "\u001b[34mCollecting sagemaker\u001b[0m\n",
      "\u001b[34mDownloading sagemaker-2.185.0.tar.gz (884 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 884.9/884.9 kB 18.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting attrs<24,>=23.1.0\u001b[0m\n",
      "\u001b[34mDownloading attrs-23.1.0-py3-none-any.whl (61 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 14.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting boto3<2.0,>=1.26.131\u001b[0m\n",
      "\u001b[34mDownloading boto3-1.28.46-py3-none-any.whl (135 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.8/135.8 kB 26.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (2.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (3.20.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smdebug_rulesconfig==1.0.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (4.13.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (23.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.5.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pathos in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: schema in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.7.5)\u001b[0m\n",
      "\u001b[34mCollecting PyYAML~=6.0\u001b[0m\n",
      "\u001b[34mDownloading PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 736.6/736.6 kB 45.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting jsonschema\u001b[0m\n",
      "\u001b[34mDownloading jsonschema-4.19.0-py3-none-any.whl (83 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.4/83.4 kB 21.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting platformdirs\u001b[0m\n",
      "\u001b[34mDownloading platformdirs-3.10.0-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mCollecting tblib==1.7.0\u001b[0m\n",
      "\u001b[34mDownloading tblib-1.7.0-py2.py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.0.1)\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.32.0,>=1.31.46\u001b[0m\n",
      "\u001b[34mDownloading botocore-1.31.46-py3-none-any.whl (11.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.2/11.2 MB 76.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.13.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from google-pasta->sagemaker) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting jsonschema-specifications>=2023.03.6\u001b[0m\n",
      "\u001b[34mDownloading jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mCollecting pkgutil-resolve-name>=1.3.10\u001b[0m\n",
      "\u001b[34mDownloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting referencing>=0.28.4\u001b[0m\n",
      "\u001b[34mDownloading referencing-0.30.2-py3-none-any.whl (25 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (5.10.2)\u001b[0m\n",
      "\u001b[34mCollecting rpds-py>=0.7.1\u001b[0m\n",
      "\u001b[34mDownloading rpds_py-0.10.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2022.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (1.7.6.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.8/site-packages (from schema->sagemaker) (21.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.32.0,>=1.31.46->boto3<2.0,>=1.26.131->sagemaker) (1.26.14)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sagemaker\u001b[0m\n",
      "\u001b[34mBuilding wheel for sagemaker (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for sagemaker (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for sagemaker: filename=sagemaker-2.185.0-py2.py3-none-any.whl size=1185833 sha256=8b09e1e0e32f0c74320c0a5977d811413b6a201cfb2165191b491a34d9521c89\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/57/8d/b9/547a120032ddd5c59ee3e2334c3fc33ac458e7a8c50a67fa5a\u001b[0m\n",
      "\u001b[34mSuccessfully built sagemaker\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tblib, rpds-py, PyYAML, platformdirs, pkgutil-resolve-name, attrs, referencing, botocore, jsonschema-specifications, jsonschema, boto3, sagemaker\u001b[0m\n",
      "\u001b[34mAttempting uninstall: PyYAML\u001b[0m\n",
      "\u001b[34mFound existing installation: PyYAML 5.4.1\u001b[0m\n",
      "\u001b[34mUninstalling PyYAML-5.4.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled PyYAML-5.4.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: attrs\u001b[0m\n",
      "\u001b[34mFound existing installation: attrs 22.2.0\u001b[0m\n",
      "\u001b[34mUninstalling attrs-22.2.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled attrs-22.2.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: botocore\u001b[0m\n",
      "\u001b[34mFound existing installation: botocore 1.29.70\u001b[0m\n",
      "\u001b[34mUninstalling botocore-1.29.70:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled botocore-1.29.70\u001b[0m\n",
      "\u001b[34mAttempting uninstall: boto3\u001b[0m\n",
      "\u001b[34mFound existing installation: boto3 1.26.70\u001b[0m\n",
      "\u001b[34mUninstalling boto3-1.26.70:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled boto3-1.26.70\u001b[0m\n",
      "\u001b[34mAttempting uninstall: sagemaker\u001b[0m\n",
      "\u001b[34mFound existing installation: sagemaker 2.132.0\u001b[0m\n",
      "\u001b[34mUninstalling sagemaker-2.132.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled sagemaker-2.132.0\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mawscli 1.27.70 requires botocore==1.29.70, but you have botocore 1.31.46 which is incompatible.\u001b[0m\n",
      "\u001b[34mawscli 1.27.70 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed PyYAML-6.0.1 attrs-23.1.0 boto3-1.28.46 botocore-1.31.46 jsonschema-4.19.0 jsonschema-specifications-2023.7.1 pkgutil-resolve-name-1.3.10 platformdirs-3.10.0 referencing-0.30.2 rpds-py-0.10.2 sagemaker-2.185.0 tblib-1.7.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.0 -> 23.2.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34mINFO:sagemaker.experiments.run:The run (run-2) under experiment (pytorch-experiments-train) already exists. Loading it.\u001b[0m\n",
      "\u001b[34mProcesses 50000/50000 (100%) of train data\u001b[0m\n",
      "\u001b[34mINFO:__main__:Processes 50000/50000 (100%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34mINFO:__main__:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34mTraining Epoch: 1\u001b[0m\n",
      "\u001b[34m[2023-09-12 20:27:17.341 algo-1:43 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[2023-09-12 20:27:17.530 algo-1:43 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-09-12 20:27:17.532 algo-1:43 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-09-12 20:27:17.532 algo-1:43 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-09-12 20:27:17.533 algo-1:43 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-09-12 20:27:17.533 algo-1:43 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [6400/50000 (13%)], Train Loss: 1.634270;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [6400/50000 (13%)], Train Loss: 1.634270;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [12800/50000 (26%)], Train Loss: 1.594734;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [12800/50000 (26%)], Train Loss: 1.594734;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [19200/50000 (38%)], Train Loss: 1.456911;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [19200/50000 (38%)], Train Loss: 1.456911;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [25600/50000 (51%)], Train Loss: 1.239556;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [25600/50000 (51%)], Train Loss: 1.239556;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [32000/50000 (64%)], Train Loss: 1.289988;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [32000/50000 (64%)], Train Loss: 1.289988;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [38400/50000 (77%)], Train Loss: 0.960770;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [38400/50000 (77%)], Train Loss: 0.960770;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [44800/50000 (90%)], Train Loss: 1.472166;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [44800/50000 (90%)], Train Loss: 1.472166;\u001b[0m\n",
      "\u001b[34mTrain Average loss: 1.1112, Train Accuracy: 59.9180%;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Average loss: 1.1112, Train Accuracy: 59.9180%;\u001b[0m\n",
      "\u001b[34mTest Average loss: 1.1567, Test Accuracy: 58.6500%;\u001b[0m\n",
      "\u001b[34mTraining Epoch: 2\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test Average loss: 1.1567, Test Accuracy: 58.6500%;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [6400/50000 (13%)], Train Loss: 1.163804;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 2 [6400/50000 (13%)], Train Loss: 1.163804;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [12800/50000 (26%)], Train Loss: 1.003564;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 2 [12800/50000 (26%)], Train Loss: 1.003564;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [19200/50000 (38%)], Train Loss: 0.970114;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 2 [19200/50000 (38%)], Train Loss: 0.970114;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [25600/50000 (51%)], Train Loss: 0.745795;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 2 [25600/50000 (51%)], Train Loss: 0.745795;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [32000/50000 (64%)], Train Loss: 1.048792;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 2 [32000/50000 (64%)], Train Loss: 1.048792;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [38400/50000 (77%)], Train Loss: 0.885853;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 2 [38400/50000 (77%)], Train Loss: 0.885853;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [44800/50000 (90%)], Train Loss: 0.883821;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 2 [44800/50000 (90%)], Train Loss: 0.883821;\u001b[0m\n",
      "\u001b[34mTrain Average loss: 0.8426, Train Accuracy: 70.4580%;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Average loss: 0.8426, Train Accuracy: 70.4580%;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.9488, Test Accuracy: 67.3500%;\u001b[0m\n",
      "\u001b[34mTraining Epoch: 3\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test Average loss: 0.9488, Test Accuracy: 67.3500%;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [6400/50000 (13%)], Train Loss: 0.761536;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 3 [6400/50000 (13%)], Train Loss: 0.761536;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [12800/50000 (26%)], Train Loss: 0.627361;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 3 [12800/50000 (26%)], Train Loss: 0.627361;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [19200/50000 (38%)], Train Loss: 0.715216;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 3 [19200/50000 (38%)], Train Loss: 0.715216;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [25600/50000 (51%)], Train Loss: 0.874957;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 3 [25600/50000 (51%)], Train Loss: 0.874957;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [32000/50000 (64%)], Train Loss: 0.666002;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 3 [32000/50000 (64%)], Train Loss: 0.666002;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [38400/50000 (77%)], Train Loss: 0.659092;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 3 [38400/50000 (77%)], Train Loss: 0.659092;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [44800/50000 (90%)], Train Loss: 0.500948;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 3 [44800/50000 (90%)], Train Loss: 0.500948;\u001b[0m\n",
      "\u001b[34mTrain Average loss: 0.5662, Train Accuracy: 80.4540%;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Average loss: 0.5662, Train Accuracy: 80.4540%;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.7059, Test Accuracy: 75.4700%;\u001b[0m\n",
      "\u001b[34mTraining Epoch: 4\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test Average loss: 0.7059, Test Accuracy: 75.4700%;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [6400/50000 (13%)], Train Loss: 0.586840;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 4 [6400/50000 (13%)], Train Loss: 0.586840;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [12800/50000 (26%)], Train Loss: 0.621406;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 4 [12800/50000 (26%)], Train Loss: 0.621406;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [19200/50000 (38%)], Train Loss: 0.668581;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 4 [19200/50000 (38%)], Train Loss: 0.668581;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [25600/50000 (51%)], Train Loss: 0.500672;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 4 [25600/50000 (51%)], Train Loss: 0.500672;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [32000/50000 (64%)], Train Loss: 0.679109;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 4 [32000/50000 (64%)], Train Loss: 0.679109;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [38400/50000 (77%)], Train Loss: 0.419288;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 4 [38400/50000 (77%)], Train Loss: 0.419288;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [44800/50000 (90%)], Train Loss: 0.459476;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 4 [44800/50000 (90%)], Train Loss: 0.459476;\u001b[0m\n",
      "\u001b[34mTrain Average loss: 0.5260, Train Accuracy: 81.5760%;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Average loss: 0.5260, Train Accuracy: 81.5760%;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.7245, Test Accuracy: 75.6300%;\u001b[0m\n",
      "\u001b[34mTraining Epoch: 5\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test Average loss: 0.7245, Test Accuracy: 75.6300%;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [6400/50000 (13%)], Train Loss: 0.626975;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 5 [6400/50000 (13%)], Train Loss: 0.626975;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [12800/50000 (26%)], Train Loss: 0.304204;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 5 [12800/50000 (26%)], Train Loss: 0.304204;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [19200/50000 (38%)], Train Loss: 0.467343;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 5 [19200/50000 (38%)], Train Loss: 0.467343;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [25600/50000 (51%)], Train Loss: 0.329323;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 5 [25600/50000 (51%)], Train Loss: 0.329323;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [32000/50000 (64%)], Train Loss: 0.534896;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 5 [32000/50000 (64%)], Train Loss: 0.534896;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [38400/50000 (77%)], Train Loss: 0.293148;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 5 [38400/50000 (77%)], Train Loss: 0.293148;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [44800/50000 (90%)], Train Loss: 0.290995;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 5 [44800/50000 (90%)], Train Loss: 0.290995;\u001b[0m\n",
      "\u001b[34mTrain Average loss: 0.4466, Train Accuracy: 84.2620%;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Average loss: 0.4466, Train Accuracy: 84.2620%;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.7110, Test Accuracy: 75.9700%;\u001b[0m\n",
      "\u001b[34mTraining Epoch: 6\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test Average loss: 0.7110, Test Accuracy: 75.9700%;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [6400/50000 (13%)], Train Loss: 0.260417;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 6 [6400/50000 (13%)], Train Loss: 0.260417;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [12800/50000 (26%)], Train Loss: 0.540432;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 6 [12800/50000 (26%)], Train Loss: 0.540432;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [19200/50000 (38%)], Train Loss: 0.354354;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 6 [19200/50000 (38%)], Train Loss: 0.354354;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [25600/50000 (51%)], Train Loss: 0.662200;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 6 [25600/50000 (51%)], Train Loss: 0.662200;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [32000/50000 (64%)], Train Loss: 0.343777;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 6 [32000/50000 (64%)], Train Loss: 0.343777;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [38400/50000 (77%)], Train Loss: 0.757180;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 6 [38400/50000 (77%)], Train Loss: 0.757180;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [44800/50000 (90%)], Train Loss: 0.332492;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 6 [44800/50000 (90%)], Train Loss: 0.332492;\u001b[0m\n",
      "\u001b[34mTrain Average loss: 0.3561, Train Accuracy: 87.6660%;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Average loss: 0.3561, Train Accuracy: 87.6660%;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.6690, Test Accuracy: 77.4000%;\u001b[0m\n",
      "\u001b[34mTraining Epoch: 7\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test Average loss: 0.6690, Test Accuracy: 77.4000%;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [6400/50000 (13%)], Train Loss: 0.446023;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 7 [6400/50000 (13%)], Train Loss: 0.446023;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [12800/50000 (26%)], Train Loss: 0.441181;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 7 [12800/50000 (26%)], Train Loss: 0.441181;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [19200/50000 (38%)], Train Loss: 0.432964;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 7 [19200/50000 (38%)], Train Loss: 0.432964;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [25600/50000 (51%)], Train Loss: 0.456026;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 7 [25600/50000 (51%)], Train Loss: 0.456026;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [32000/50000 (64%)], Train Loss: 0.247505;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 7 [32000/50000 (64%)], Train Loss: 0.247505;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [38400/50000 (77%)], Train Loss: 0.370142;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 7 [38400/50000 (77%)], Train Loss: 0.370142;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [44800/50000 (90%)], Train Loss: 0.483520;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 7 [44800/50000 (90%)], Train Loss: 0.483520;\u001b[0m\n",
      "\u001b[34mTrain Average loss: 0.3332, Train Accuracy: 88.3000%;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Average loss: 0.3332, Train Accuracy: 88.3000%;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.6926, Test Accuracy: 77.2800%;\u001b[0m\n",
      "\u001b[34mTraining Epoch: 8\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test Average loss: 0.6926, Test Accuracy: 77.2800%;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [6400/50000 (13%)], Train Loss: 0.362336;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 8 [6400/50000 (13%)], Train Loss: 0.362336;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [12800/50000 (26%)], Train Loss: 0.425544;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 8 [12800/50000 (26%)], Train Loss: 0.425544;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [19200/50000 (38%)], Train Loss: 0.195796;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 8 [19200/50000 (38%)], Train Loss: 0.195796;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [25600/50000 (51%)], Train Loss: 0.335110;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 8 [25600/50000 (51%)], Train Loss: 0.335110;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [32000/50000 (64%)], Train Loss: 0.331010;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 8 [32000/50000 (64%)], Train Loss: 0.331010;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [38400/50000 (77%)], Train Loss: 0.282124;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 8 [38400/50000 (77%)], Train Loss: 0.282124;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [44800/50000 (90%)], Train Loss: 0.454924;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 8 [44800/50000 (90%)], Train Loss: 0.454924;\u001b[0m\n",
      "\u001b[34mTrain Average loss: 0.2156, Train Accuracy: 92.6760%;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Average loss: 0.2156, Train Accuracy: 92.6760%;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.6461, Test Accuracy: 79.2200%;\u001b[0m\n",
      "\u001b[34mTraining Epoch: 9\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test Average loss: 0.6461, Test Accuracy: 79.2200%;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [6400/50000 (13%)], Train Loss: 0.139726;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 9 [6400/50000 (13%)], Train Loss: 0.139726;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [12800/50000 (26%)], Train Loss: 0.262899;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 9 [12800/50000 (26%)], Train Loss: 0.262899;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [19200/50000 (38%)], Train Loss: 0.241475;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 9 [19200/50000 (38%)], Train Loss: 0.241475;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [25600/50000 (51%)], Train Loss: 0.325232;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 9 [25600/50000 (51%)], Train Loss: 0.325232;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [32000/50000 (64%)], Train Loss: 0.386382;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 9 [32000/50000 (64%)], Train Loss: 0.386382;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [38400/50000 (77%)], Train Loss: 0.318046;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 9 [38400/50000 (77%)], Train Loss: 0.318046;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [44800/50000 (90%)], Train Loss: 0.279704;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 9 [44800/50000 (90%)], Train Loss: 0.279704;\u001b[0m\n",
      "\u001b[34mTrain Average loss: 0.2078, Train Accuracy: 92.6860%;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Average loss: 0.2078, Train Accuracy: 92.6860%;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.7212, Test Accuracy: 78.5500%;\u001b[0m\n",
      "\u001b[34mTraining Epoch: 10\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test Average loss: 0.7212, Test Accuracy: 78.5500%;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [6400/50000 (13%)], Train Loss: 0.167086;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 10 [6400/50000 (13%)], Train Loss: 0.167086;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [12800/50000 (26%)], Train Loss: 0.161049;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 10 [12800/50000 (26%)], Train Loss: 0.161049;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [19200/50000 (38%)], Train Loss: 0.229876;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 10 [19200/50000 (38%)], Train Loss: 0.229876;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [25600/50000 (51%)], Train Loss: 0.178716;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 10 [25600/50000 (51%)], Train Loss: 0.178716;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [32000/50000 (64%)], Train Loss: 0.249512;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 10 [32000/50000 (64%)], Train Loss: 0.249512;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [38400/50000 (77%)], Train Loss: 0.144232;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 10 [38400/50000 (77%)], Train Loss: 0.144232;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [44800/50000 (90%)], Train Loss: 0.193804;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 10 [44800/50000 (90%)], Train Loss: 0.193804;\u001b[0m\n",
      "\u001b[34mTrain Average loss: 0.1450, Train Accuracy: 95.2760%;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Average loss: 0.1450, Train Accuracy: 95.2760%;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.6869, Test Accuracy: 79.0400%;\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test Average loss: 0.6869, Test Accuracy: 79.0400%;\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34mINFO:__main__:Saving the model.\u001b[0m\n",
      "\u001b[34m2023-09-12 20:47:50,676 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-09-12 20:47:50,677 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-09-12 20:47:50,677 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-09-12 20:48:10 Uploading - Uploading generated training model\n",
      "2023-09-12 20:48:10 Completed - Training job completed\n",
      "Training seconds: 1367\n",
      "Billable seconds: 1367\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Set role for train job\n",
    "role = get_execution_role()\n",
    "\n",
    "experiment_name = \"pytorch-experiments-train\"\n",
    "\n",
    "# Param Grid\n",
    "for params in param_combinations:\n",
    "        run_id += 1\n",
    "        run_name = \"run-\" + str(run_id)\n",
    "        print(run_name)\n",
    "    \n",
    "        # Sagemaker Run\n",
    "        with Run(experiment_name=experiment_name, \n",
    "                     run_name=run_name, \n",
    "                     sagemaker_session=Session()) as run:\n",
    "            \n",
    "            # Estimator\n",
    "            est = PyTorch(\n",
    "                entry_point=\"./script/toy_model.py\", # train script\n",
    "                role=role,\n",
    "                model_dir=\"/opt/ml/model/\", # dir inside container\n",
    "                framework_version=\"1.12\",\n",
    "                py_version=\"py38\",\n",
    "                instance_type=\"ml.m5.xlarge\", # $0.23 / hr\n",
    "                instance_count=1,\n",
    "                hyperparameters = params,\n",
    "                keep_alive_period_in_seconds=3600,\n",
    "                output_path = \"s3://pytorch-aws-train-deploy-project/training/\"\n",
    "            )\n",
    "\n",
    "            est.fit(\n",
    "            inputs={\n",
    "                        'training': full_train_s3_path,\n",
    "                        'validation': full_val_s3_path \n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e0f0a5-c58f-45ab-b40f-08646bc7e275",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:10px; font-size:20px\">\n",
    "Clear SageMaker Experiment Data (skip)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2deb2af-98f1-4726-8bb5-c81e0ead3b7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install sagemaker-experiments"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be4cab41-4c27-45d5-b7e7-d787b22bf060",
   "metadata": {
    "tags": []
   },
   "source": [
    "import time\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c96acec1-b3d2-4bf8-8aac-7838c68f6fea",
   "metadata": {
    "tags": []
   },
   "source": [
    "def cleanup_sme_sdk(experiment):\n",
    "    for trial_summary in experiment.list_trials():\n",
    "        trial = Trial.load(trial_name=trial_summary.trial_name)\n",
    "        for trial_component_summary in trial.list_trial_components():\n",
    "            tc = TrialComponent.load(\n",
    "                trial_component_name=trial_component_summary.trial_component_name)\n",
    "            trial.remove_trial_component(tc)\n",
    "            try:\n",
    "                # comment out to keep trial components\n",
    "                tc.delete()\n",
    "            except:\n",
    "                # tc is associated with another trial\n",
    "                continue\n",
    "            # to prevent throttling\n",
    "            time.sleep(.5)\n",
    "        trial.delete()\n",
    "        experiment_name = experiment.experiment_name\n",
    "    experiment.delete()\n",
    "    print(f\"\\nExperiment {experiment_name} deleted\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d77c5d4b-4408-4159-b2f2-b37857de1114",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "experiment_to_cleanup = Experiment.load(\n",
    "    # Use experiment name not display name\n",
    "    experiment_name=\"experiment-name\")\n",
    "\n",
    "cleanup_sme_sdk(experiment_to_cleanup)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.12 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.12-cpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
